import os
import sys
from typing import List, Dict
import yaml
import json
import time
import re
import importlib
import inspect
import pkgutil
from lazyllm.module.onlineChatModule.onlineChatModule import OnlineChatModule
from lazyllm import ReactAgent
from lazyllm import fc_register, LOG
from ..manager.custom import CustomManager
from .prompt import (
    README_PROMPT,
    GITIGNORE_PROMPT,
    LICENSE_PROMPT,
    generate_mkdocs_config,
    MKDOCS_PROMPT,
    TRANSLATE_PROMPT,
    PLUGIN_CONFIG,
)


class GitAgent:
    """GitAgentç±»ç”¨äºè‡ªåŠ¨åŒ–ç®¡ç†Gité¡¹ç›®çš„æ ‡å‡†åŒ–æµç¨‹ï¼ŒåŒ…æ‹¬æ–‡æ¡£ç”Ÿæˆã€é¡¹ç›®ç»“æ„åˆ†æç­‰åŠŸèƒ½ã€‚"""
    def __init__(self, project_path: str, llm: OnlineChatModule, language: str = "zh"):
        """åˆå§‹åŒ–GitAgentå®ä¾‹ã€‚
        
        Args:
            project_path (str): é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ã€‚
            llm (OnlineChatModule): è¯­è¨€æ¨¡å‹å®ä¾‹ã€‚
            language (str): æ”¯æŒçš„è¯­è¨€ç±»å‹ï¼Œé»˜è®¤ä¸º'zh'ï¼ˆä¸­æ–‡ï¼‰ã€‚
        
        å¼‚å¸¸:
            ValueError: å½“é¡¹ç›®è·¯å¾„ä¸å­˜åœ¨æˆ–è¯­è¨€ä¸æ”¯æŒæ—¶æŠ›å‡ºã€‚"""
        self.project_path = os.path.abspath(project_path)
        if not os.path.exists(self.project_path):
            raise ValueError(f"Project path does not exist: {self.project_path}")

        self.supported_languages = {"zh", "en", "bilingual"}
        if language not in self.supported_languages:
            raise ValueError(f"Unsupported language: {language}. "
                             f"Please choose from {self.supported_languages}.")
        self.language = language

        self.docstring_manager = CustomManager(
            llm=llm, pattern="fill", skip_on_error=True, language=language
        )
        self.module_dict = {}
        self.module_doc_dict = {}
        if self.project_path not in sys.path:
            sys.path.append(self.project_path)
        self._gen_module_dict()
        self.llm = llm
        self.tool_registered = False

    def standardize_project(self, gen_docstrings: bool = True, gen_mkdocs: bool = True) -> None:
        """æ‰§è¡Œé¡¹ç›®æ ‡å‡†åŒ–æµç¨‹ã€‚
        
        Args:
            gen_docstrings (bool): æ˜¯å¦ç”Ÿæˆæ–‡æ¡£å­—ç¬¦ä¸²ï¼Œé»˜è®¤ä¸ºTrueã€‚
            gen_mkdocs (bool): æ˜¯å¦ç”ŸæˆMkDocsæ–‡æ¡£ï¼Œé»˜è®¤ä¸ºTrueã€‚"""
        self._generate_requirements()
        self._generate_gitignore()
        if gen_docstrings:
            self._generate_docstring()
            self._update_module_dict()
        self._generate_readme()
        if gen_mkdocs:
            self._generate_mkdocs()
        LOG.info("âœ¨Project standardization completed")

    def _generate_docstring(self) -> None:
        """è‡ªåŠ¨ä¸ºé¡¹ç›®ä¸­çš„æ‰€æœ‰æ¨¡å—ç”Ÿæˆæ–‡æ¡£å­—ç¬¦ä¸²ã€‚"""
        LOG.info("ğŸ˜Š Automatically generating doctring...")
        for _, module in self.module_dict.items():
            if "children" in module:
                self.docstring_manager.traverse(module["obj"])
            else:
                self.docstring_manager.modify_docstring(module["obj"])
        LOG.info("âœ… Doctring generation completed...")

    def _register_tools(self):
        """æ³¨å†Œå·¥å…·å‡½æ•°ï¼ŒåŒ…æ‹¬è·å–æ¨¡å—æ–‡æ¡£å’Œå†™å…¥æ–‡æ¡£åŠŸèƒ½ã€‚"""
        if self.tool_registered:
            return

        @fc_register("tool")
        def get_module_doc(module_name: str) -> str:
            """
            Get module's docstring by module name.
            Args:
                module_name (str): Complete module name, from top-level to bottom-level,
                                separated by dots (.), e.g. "a.b.c".
            Returns:
                str: Module's docstring
            """
            LOG.info(f"module_name: {module_name}")
            if module_name not in self.module_doc_dict:
                return f"Module {module_name} does not exist"
            return self.module_doc_dict[module_name][:2000]

        @fc_register("tool")
        def write_doc(path: str, content: str) -> str:
            """
            Write given content to file at specified path.
            Args:
                path (str): Target file's relative path (based on project root).
                content (str): Text content to write.
            Returns:
                str: Returns 'success' if successful, error message if failed.
            """
            LOG.info(f"write_doc: {path}")
            try:
                path = os.path.join(self.project_path, path.strip("/"))
                if not os.path.exists(os.path.dirname(path)):
                    os.makedirs(os.path.dirname(path), exist_ok=True)
                with open(path, "w", encoding="utf-8") as f:
                    f.write(content)
                LOG.info(f"write_doc {path} success")
                return "success"
            except Exception as e:
                LOG.info(f"write_doc {path} error {e}")
                return f"Error writing file: {str(e)}"

        self.tool_registered = True

    def _generate_mkdocs(self):
        """ç”ŸæˆMkDocsæ–‡æ¡£ç½‘ç«™ã€‚
        
        å¤„ç†åŒè¯­æ–‡æ¡£ç”Ÿæˆå’Œé…ç½®æ–‡ä»¶æ›´æ–°ã€‚"""
        LOG.info("ğŸ˜Š Generating mkdocs...")
        self._register_tools()
        agent = ReactAgent(llm=self.llm, tools=["get_module_doc", "write_doc"], max_retries=20)
        project_structure = self._generate_project_tree(
            module_list=self.module_doc_dict.keys()
        )
        language = "en" if self.language == "en" else "zh"
        query = MKDOCS_PROMPT.format(
            project_structure=project_structure,
            mkdocs_config=generate_mkdocs_config(
                site_name=os.path.basename(self.project_path),
                docs_dir=f"docs/{language}",
            ),
            language=language,
            language_type="è‹±æ–‡" if self.language == "en" else "ä¸­æ–‡",
            docs_dir="zh",
        )
        LOG.info(agent(query))
        try:
            if self.language == "bilingual":
                docs_dir_zh = os.path.join(self.project_path, "docs", "zh")
                docs_dir_en = os.path.join(self.project_path, "docs", "en")
                self._translate_docs(docs_dir_zh, docs_dir_en)
                if not os.path.exists(os.path.join(self.project_path, "mkdocs.yml")):
                    return
                with open(os.path.join(self.project_path, "mkdocs.yml"), "r", encoding="utf-8") as file:
                    config = yaml.safe_load(file)
                config["docs_dir"] = "docs"
                config["plugins"] = PLUGIN_CONFIG
                with open(
                    os.path.join(self.project_path, "mkdocs.yml"), "w", encoding="utf-8"
                ) as file:
                    yaml.dump(config, file, allow_unicode=True, sort_keys=False)
        except Exception as e:
            LOG.info(f" â— (Error during generating mkdocs {e}")
        LOG.info("âœ… mkdocs generation completed...")

    def start_mkdocs_server(self, port=8333) -> None:
        """å¯åŠ¨MkDocsæœ¬åœ°æœåŠ¡å™¨ã€‚
        
        Args:
            port (int): æœåŠ¡å™¨ç«¯å£å·ï¼Œé»˜è®¤ä¸º8333ã€‚
        
        å¼‚å¸¸:
            ValueError: å½“æ–‡æ¡£ç›®å½•æˆ–é…ç½®æ–‡ä»¶ä¸å­˜åœ¨æ—¶æŠ›å‡ºã€‚"""
        docs_dir_base = os.path.join(self.project_path, "docs")
        if not os.path.exists(docs_dir_base) or not os.path.exists(os.path.join(self.project_path, "mkdocs.yml")):
            raise ValueError("Documentation directory or mkdocs.yml file does not exist, \
                    please generate automatically or manually first.")

        current_dir = os.getcwd()
        try:
            import subprocess
            import atexit

            os.chdir(self.project_path)
            LOG.info("âœ… Documentation generation completed, starting mkdocs service")
            mkdocs_process = subprocess.Popen(
                [
                    "mkdocs",
                    "serve",
                    "-f",
                    os.path.join(docs_dir_base, "mkdocs.yml"),
                    "-a",
                    f"0.0.0.0:{port}",
                ],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )

            def cleanup():
                mkdocs_process.terminate()
                mkdocs_process.wait()

            atexit.register(cleanup)
            LOG.info(f"mkdocs æœåŠ¡å™¨å·²å¯åŠ¨ï¼Œè¯·è®¿é—® http://localhost:{port}")
            time.sleep(600)
        except Exception as e:
            LOG.info(f"å¯åŠ¨ mkdocs æœåŠ¡å™¨æ—¶å‡ºé”™: {str(e)}")
        finally:
            os.chdir(current_dir)

    def _generate_project_tree(self, module_list: list) -> str:
        """ç”Ÿæˆé¡¹ç›®ç»“æ„æ ‘ã€‚
        
        Args:
            module_list (list): æ¨¡å—è·¯å¾„åˆ—è¡¨ã€‚
        
        Returns:
            str: æ ¼å¼åŒ–åçš„é¡¹ç›®ç»“æ„æ ‘å­—ç¬¦ä¸²ã€‚"""
        tree_dict = {}
        for module_path in module_list:
            parts = module_path.split(".")
            current = tree_dict
            for i, part in enumerate(parts):
                if part not in current:
                    current[part] = {}
                current = current[part]

        def process_tree_dict(tree_dict, level=0):
            """å°†å­—å…¸ç»“æ„çš„æ ‘å½¢æ•°æ®è½¬æ¢ä¸ºå¸¦ç¼©è¿›çš„åˆ—è¡¨å½¢å¼è¡¨ç¤ºã€‚
    
            Args:
                tree_dict (dict): æ ‘å½¢ç»“æ„çš„å­—å…¸ï¼Œé”®ä¸ºèŠ‚ç‚¹åç§°ï¼Œå€¼ä¸ºå­èŠ‚ç‚¹å­—å…¸
                level (int): å½“å‰èŠ‚ç‚¹çš„å±‚çº§ï¼Œç”¨äºæ§åˆ¶ç¼©è¿›é‡ï¼Œé»˜è®¤ä¸º0
            
            Returns:
                list: åŒ…å«æ ¼å¼åŒ–åæ ‘å½¢ç»“æ„çš„å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä»£è¡¨ä¸€ä¸ªèŠ‚ç‚¹è¡Œ"""
            tree = []
            indent = "  " * level
            for name, children in sorted(tree_dict.items()):
                if children:
                    tree.append(f"{indent}- {name}/")
                    tree.extend(process_tree_dict(children, level + 1))
                else:
                    tree.append(f"{indent}- {name}")
            return tree

        tree = process_tree_dict(tree_dict)
        return "\n".join(tree)

    def _generate_readme(self) -> None:
        """ç”Ÿæˆé¡¹ç›®README.mdæ–‡ä»¶ã€‚"""
        LOG.info("ğŸ˜Š Generating README.md...")
        readme_path = os.path.join(self.project_path, "README.md")
        if os.path.exists(readme_path):
            LOG.info("âœ… README.md already exists, skipping generation")
            return

        project_structure = self._generate_project_tree(self.module_doc_dict.keys())
        self._register_tools()
        prompt = README_PROMPT.format(
            project_structure=json.dumps(
                project_structure, indent=2, ensure_ascii=False
            ),
            language="ä¸­æ–‡" if self.language == "zh" else "è‹±æ–‡",
        )
        agent = ReactAgent(llm=self.llm, tools=["get_module_doc"], max_retries=20)
        readme_content = agent(prompt)
        readme_content = re.sub(
            r"^<think>.*?</think>\s*",
            "",
            readme_content,
            flags=re.MULTILINE | re.DOTALL,
        )

        with open(readme_path, "w", encoding="utf-8") as f:
            f.write(readme_content)
        LOG.info("âœ… README.md generation completed")

    def _generate_gitignore(self) -> None:
        """ç”Ÿæˆ.gitignoreæ–‡ä»¶ã€‚"""
        LOG.info("ğŸ˜Š Generating .gitignore...")
        gitignore_path = os.path.join(self.project_path, ".gitignore")
        if os.path.exists(gitignore_path):
            LOG.info("âœ… .gitignore already exists, skipping generation")
            return

        project_info = self._analyze_project_type()

        prompt = GITIGNORE_PROMPT.format(
            project_info=json.dumps(project_info, indent=2, ensure_ascii=False)
        )
        gitignore_content = self.llm(prompt)

        with open(gitignore_path, "w", encoding="utf-8") as f:
            f.write(gitignore_content)
        LOG.info("âœ… .gitignore generation completed")

    def _generate_module_doc_dict(self, module_dict):
        """æ„å»ºæ¨¡å—æ–‡æ¡£å­—å…¸ã€‚
        
        Args:
            module_dict: æ¨¡å—ä¿¡æ¯å­—å…¸ã€‚"""
        def add_doc(name: str, subname: str, doc: str, level: str = "#"):
            """ä¸ºæ¨¡å—æˆ–ç±»æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²åˆ°æ–‡æ¡£å­—å…¸ä¸­ã€‚
    
            Args:
                name (str): æ¨¡å—æˆ–ç±»åç§°ï¼Œä½œä¸ºå­—å…¸çš„é”®
                subname (str): æ–‡æ¡£å­æ ‡é¢˜åç§°
                doc (str): è¦æ·»åŠ çš„æ–‡æ¡£å­—ç¬¦ä¸²å†…å®¹
                level (str): æ ‡é¢˜çº§åˆ«æ ‡è®°ï¼Œé»˜è®¤ä¸º"#"ï¼ˆä¸€çº§æ ‡é¢˜ï¼‰"""
            if name not in self.module_doc_dict:
                self.module_doc_dict[name] = ""
            self.module_doc_dict[name] += f"{level} {subname}:\n{doc or ''}\n\n"

        for name, info in module_dict.items():
            if doc := info.get("doc"):
                add_doc(name, name, doc)
            if "module" in info:
                for module_name, module_info in info["module"].items():
                    add_doc(module_name, module_name, module_info.get("doc", ""))
                    for obj_name, obj_info in module_info.items():
                        obj_name = obj_name.split(".")[-1]
                        if isinstance(obj_info, dict):
                            add_doc(
                                module_name, obj_name, obj_info.get("doc", ""), "##"
                            )
                            if "method" in obj_info:
                                for func_name, func_info in obj_info["method"].items():
                                    method_name = (
                                        f"{obj_name}.{func_name.split('.')[-1]}"
                                    )
                                    add_doc(
                                        module_name,
                                        method_name,
                                        func_info.get("doc", ""),
                                        "###",
                                    )

            if "children" in info:
                self._generate_module_doc_dict(info["children"])

    def _generate_requirements(self) -> None:
        """ç”Ÿæˆrequirements.txtæ–‡ä»¶ã€‚"""
        req_path = os.path.join(self.project_path, "requirements.txt")
        if os.path.exists(req_path):
            LOG.info("âœ… requirements.txt already exists, skipping generation")
            return
        LOG.info("ğŸ˜Š Generating requirements.txt...")
        dependencies = self._analyze_dependencies()
        project_modules = self.module_dict.keys()
        for dep in dependencies:
            if any(dep.startswith(mod) for mod in project_modules):
                dependencies.remove(dep)
        with open(req_path, "w", encoding="utf-8") as f:
            f.write("\n".join(dependencies))
        LOG.info("âœ… requirements.txt generation completed")

    def _update_module_dict(self):
        """æ›´æ–°æ¨¡å—å­—å…¸ï¼Œé‡æ–°åŠ è½½é¡¹ç›®æ¨¡å—ã€‚"""
        project_modules = self.module_dict.keys()
        modules_to_del = []
        for name in sys.modules:
            if any(name.startswith(mod) for mod in project_modules):
                modules_to_del.append(name)
        for module in modules_to_del:
            del sys.modules[module]
        self._gen_module_dict()

    def _gen_module_dict(self):
        """åˆ†æé¡¹ç›®ç»“æ„å¹¶ç”Ÿæˆæ¨¡å—å­—å…¸ã€‚"""
        LOG.info("ğŸ˜Š Analyzing project structure...")
        processed_packages = set()
        for root, dirs, files in os.walk(self.project_path):
            dirs[:] = [d for d in dirs
                       if not d.startswith(".") and d not in ["__pycache__", "tests", "docs"]]

            if "__init__.py" in files:
                rel_path = os.path.relpath(root, self.project_path)
                module_name = rel_path.replace(os.sep, ".")
                try:
                    module = importlib.import_module(module_name)
                    skip_modules = ["docs", "test", "tests"]
                    if ".".join(module_name.split(".")[:-1]) in processed_packages:
                        continue
                    self.module_dict |= self._process_package(module, skip_modules)
                    processed_packages.add(module_name)
                except Exception as e:
                    LOG.info(f"Processing module {module_name} error: {str(e)}")

            for file in files:
                if file.endswith(".py") and file not in {"__init__.py", "setup.py",
                                                         "conftest.py", "wsgi.py", "asgi.py"}:
                    rel_dir = os.path.relpath(root, self.project_path)
                    package_name = rel_dir.replace(os.sep, ".")
                    if package_name in processed_packages:
                        continue
                    module_path = os.path.join(root, file)
                    module_name = os.path.splitext(file)[0]
                    try:
                        spec = importlib.util.spec_from_file_location(module_name, module_path)
                        module = importlib.util.module_from_spec(spec)
                        self.module_dict |= self._process_module(module)

                    except Exception as e:
                        LOG.info(f"Error processing module {module_name}: {str(e)}")
        self._generate_module_doc_dict(self.module_dict)
        LOG.info("âœ… Project structure analysis completed...")

    def _process_module(self, module, f_module_name: str = "") -> Dict:
        """å¤„ç†å•ä¸ªæ¨¡å—ï¼Œæå–ç±»å’Œå‡½æ•°ä¿¡æ¯ã€‚
        
        Args:
            module: è¦å¤„ç†çš„æ¨¡å—å¯¹è±¡ã€‚
            f_module_name: æ¨¡å—å®Œæ•´åç§°å‰ç¼€ã€‚
        
        Returns:
            Dict: åŒ…å«æ¨¡å—ä¿¡æ¯çš„å­—å…¸ã€‚"""
        def _get_abs_name(obj_name):
            return f"{f_module_name}.{obj_name}".lstrip('.')
        m_dict = {"obj": module}
        for name, obj in inspect.getmembers(module, inspect.isclass):
            if not getattr(obj, "__module__", "").startswith(module.__name__):
                continue
            c_dict = {"doc": obj.__doc__, "obj": obj, "method": {}}
            for method_name, method_obj in inspect.getmembers(obj, inspect.isfunction):
                c_dict["method"][_get_abs_name(f"{name}.{method_name}")] = {"doc": method_obj.__doc__,
                                                                            "obj": method_obj}
            m_dict[_get_abs_name(name)] = c_dict
        for name, obj in inspect.getmembers(module, inspect.isfunction):
            if not getattr(obj, "__module__", "").startswith(module.__name__):
                continue
            m_dict[f"{f_module_name}.{name}"] = {"doc": obj.__doc__, "obj": obj}
        if not m_dict:
            return {}
        return {module.__name__: m_dict}

    def _process_package(self, module, skip_modules) -> Dict:
        """å¤„ç†PythonåŒ…ï¼Œé€’å½’åˆ†æå­æ¨¡å—ã€‚
        
        Args:
            module: åŒ…æ¨¡å—å¯¹è±¡ã€‚
            skip_modules: è¦è·³è¿‡çš„æ¨¡å—åå‰ç¼€åˆ—è¡¨ã€‚
        
        Returns:
            Dict: åŒ…å«åŒ…ä¿¡æ¯çš„å­—å…¸ã€‚"""
        m_dict = {"obj": module, "children": {}, "module": {}}
        processed_module = set()
        for importer, modname, ispkg in pkgutil.walk_packages(module.__path__, module.__name__ + "."):
            if any(modname.startswith(skip_mod) for skip_mod in skip_modules):
                continue
            if ispkg:
                m_dict["children"] |= self._process_package(importer.find_module(modname).load_module(modname),
                                                            skip_modules)
                processed_module.add(modname)
                continue
            try:
                submodule = importlib.import_module(modname)
                if any(modname.startswith(mod) for mod in processed_module):
                    continue
                m_dict["module"] |= self._process_module(submodule, f_module_name=modname)
            except Exception as e:
                LOG.info(f"Skipping {modname} due to import error", e)
        if not m_dict["children"] and not m_dict["module"]:
            return {}
        return {module.__name__: m_dict}

    def _analyze_project_structure(self) -> Dict:
        """åˆ†æé¡¹ç›®ç»“æ„ã€‚
        
        Returns:
            Dict: é¡¹ç›®ç»“æ„å­—å…¸ã€‚"""
        def pro_dict(d):
            for name, module in d.items():
                if "obj" in module:
                    del module["obj"]
                if "children" in module:
                    pro_dict(module["children"])
                if "method" in module:
                    pro_dict(module["method"])

        pro_dict(self.module_dict)
        return self.module_dict

    def _analyze_dependencies(self) -> List[str]:
        """åˆ†æé¡¹ç›®ä¾èµ–ã€‚
        
        Returns:
            List[str]: ä¾èµ–åŒ…åç§°åˆ—è¡¨ã€‚"""
        dependencies = set()
        for root, _, files in os.walk(self.project_path):
            for file in files:
                if file.endswith(".py"):
                    with open(os.path.join(root, file), "r", encoding="utf-8") as f:
                        content = f.read()
                        for line in content.split("\n"):
                            if line.startswith(("import ", "from ")):
                                module = line.split()[1].split(".")[0]
                                if not self._is_standard_library(module):
                                    dependencies.add(module)
        return list(dependencies)

    def _analyze_project_type(self) -> Dict:
        """åˆ†æé¡¹ç›®ç±»å‹ä¿¡æ¯ã€‚
        
        Returns:
            Dict: åŒ…å«é¡¹ç›®ç±»å‹ç‰¹å¾ä¿¡æ¯çš„å­—å…¸ã€‚"""
        file_extensions = set()
        for root, _, files in os.walk(self.project_path):
            for file in files:
                ext = os.path.splitext(file)[1]
                if ext:
                    file_extensions.add(ext[1:])  # ç§»é™¤ç‚¹å·

        return {
            "languages": list(file_extensions),
            "has_setup_py": os.path.exists(os.path.join(self.project_path, "setup.py")),
            "has_requirements": os.path.exists(
                os.path.join(self.project_path, "requirements.txt")
            ),
            "has_tests": any(
                d.startswith("test") for d in os.listdir(self.project_path)
            ),
        }

    @staticmethod
    def _is_standard_library(module_name: str) -> bool:
        """æ£€æŸ¥æ¨¡å—æ˜¯å¦å±äºPythonæ ‡å‡†åº“ã€‚
        
        Args:
            module_name: æ¨¡å—åç§°ã€‚
        
        Returns:
            bool: å¦‚æœæ˜¯æ ‡å‡†åº“æ¨¡å—è¿”å›Trueï¼Œå¦åˆ™è¿”å›Falseã€‚"""
        return module_name in sys.stdlib_module_names

    def _translate_docs(self, docs_dir_zh: str, docs_dir_en: str) -> None:
        """
        Translate Chinese documents into English documents, keeping the original directory structure.
        """
        os.makedirs(docs_dir_en, exist_ok=True)

        for root, dirs, files in os.walk(docs_dir_zh):
            rel_path = os.path.relpath(root, docs_dir_zh)
            en_dir = os.path.join(docs_dir_en, rel_path)
            os.makedirs(en_dir, exist_ok=True)

            for file in files:
                if not file.endswith(".md"):
                    continue

                zh_file_path = os.path.join(root, file)
                en_file_path = os.path.join(en_dir, file)

                with open(zh_file_path, "r", encoding="utf-8") as f:
                    zh_content = f.read()

                query = TRANSLATE_PROMPT.format(zh_content=zh_content)
                en_content = self.llm(query, enable_thinking=False)

                with open(en_file_path, "w", encoding="utf-8") as f:
                    f.write(en_content)

                LOG.info(
                    f"Translated doc file: {os.path.relpath(zh_file_path, self.project_path)} -> \
                    {os.path.relpath(en_file_path, self.project_path)}"
                )
